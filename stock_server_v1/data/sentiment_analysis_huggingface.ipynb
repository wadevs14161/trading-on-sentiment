{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17eb70a1-ebb6-4e1f-a32a-65798a8f8c35",
   "metadata": {},
   "source": [
    "### Huggingface model\n",
    "- cardiffnlp/twitter-roberta-base-sentiment (58M)\n",
    "- spacesedan/reddit-sentiment-analysis-longformer (149M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52b6f1f1-404c-40c1-af32-ce8b4411f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be9fde8b-f0a6-4651-9465-a2ce372be43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reddit_sentiment_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02cda2a8-265a-4831-abe5-d2765135f2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55546, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75fe7515-41a0-45ee-8687-22aa6ecb4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for sentiment analysis\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ed8cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bbfaf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model...\n",
      "Labels: ['negative', 'neutral', 'positive']\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the RoBERTa sentiment model\n",
    "task = 'sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "print(\"Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Download label mapping\n",
    "labels = []\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "print(f\"Labels: {labels}\")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c34306d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment score (0=Negative, 1=Neutral, 2=Positive)\n",
    "def get_sentiment_score(text):\n",
    "    if pd.isna(text) or text == '' or str(text).strip() == '':\n",
    "        return 0  # Return 0 (Negative) for NaN or empty values\n",
    "    \n",
    "    try:\n",
    "        # Preprocess the text\n",
    "        processed_text = preprocess(str(text))\n",
    "        \n",
    "        # Tokenize and get model prediction\n",
    "        encoded_input = tokenizer(processed_text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        \n",
    "        # Get the predicted class (0=Negative, 1=Neutral, 2=Positive)\n",
    "        predicted_class = np.argmax(scores)\n",
    "        return int(predicted_class)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(text)[:50]}... - {e}\")\n",
    "        return 0  # Return 0 (Negative) for errors as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cb956f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment for titles...\n",
      "Analyzing sentiment for bodies...\n",
      "Sentiment analysis complete!\n",
      "CPU times: user 1h 59min 51s, sys: 31min 44s, total: 2h 31min 35s\n",
      "Wall time: 1h 39min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Apply sentiment analysis to title and body columns\n",
    "print(\"Analyzing sentiment for titles...\")\n",
    "df['title_score_roberta'] = df['title'].apply(get_sentiment_score)\n",
    "\n",
    "print(\"Analyzing sentiment for bodies...\")\n",
    "df['body_score_roberta'] = df['body'].apply(get_sentiment_score)\n",
    "\n",
    "print(\"Sentiment analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ba95fbd-3d0a-4140-a8ce-04d39ecec4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reddit_sentiment_data_models.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56b86d7b-4f22-4a78-b01d-2394d05c1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8f3b838-aa12-4d51-a4c5-290b3c90d076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'score', 'comms_num', 'body', 'date', 'stock',\n",
       "       'title_sentiment', 'body_sentiment', 'title_score_roberta',\n",
       "       'body_score_roberta'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a2ccf4e-53d1-4009-b434-c779c09607b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=55546, step=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c4b51-d7fe-4522-a786-827d997b7b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9200de3-2f7c-4de8-bfd2-a07c098f2c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
